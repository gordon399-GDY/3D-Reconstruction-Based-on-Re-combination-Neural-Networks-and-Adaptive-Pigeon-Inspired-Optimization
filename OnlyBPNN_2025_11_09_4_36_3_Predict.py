import torch
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler


class BPNeuralNetwork(torch.nn.Module):
    def __init__(self, input_size, hidden_layers, output_size):
        super(BPNeuralNetwork, self).__init__()
        layers = []

        # 输入层到隐藏层
        layers.append(torch.nn.Linear(input_size, hidden_layers[0]))
        layers.append(torch.nn.Tanh())  # 使用tanh激活函数

        # 隐藏层到输出层
        layers.append(torch.nn.Linear(hidden_layers[0], output_size))
        # 输出层不使用激活函数，因为这是回归问题

        self.network = torch.nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)


def load_model(model_path):
    """加载训练好的模型"""
    checkpoint = torch.load(model_path, map_location='cpu')

    # 创建模型实例
    input_size = 4
    hidden_layers = [36]  # 网络结构 [4, 36, 3]
    output_size = 3

    model = BPNeuralNetwork(input_size, hidden_layers, output_size)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()  # 设置为评估模式

    # 加载标准化器
    scaler_X = checkpoint['scaler_X']
    scaler_y = checkpoint['scaler_y']

    return model, scaler_X, scaler_y


def predict_with_model(model, scaler_X, scaler_y, input_data):
    """使用模型进行预测"""
    # 数据标准化
    input_scaled = scaler_X.transform(input_data)

    # 转换为PyTorch张量
    input_tensor = torch.FloatTensor(input_scaled)

    # 预测
    with torch.no_grad():
        output_scaled = model(input_tensor).numpy()

    # 反标准化
    output = scaler_y.inverse_transform(output_scaled)

    return output


def main():
    # 加载模型
    model_path = 'Only_bpnn_model.pth'
    try:
        model, scaler_X, scaler_y = load_model(model_path)
        print("模型加载成功!")
        print(f"网络结构: [4, 36, 3]")
        print(f"激活函数: tanh")
        print(f"目标损失: 1.05e-04")
    except FileNotFoundError:
        print(f"错误: 找不到模型文件 '{model_path}'")
        return
    except Exception as e:
        print(f"加载模型时出错: {e}")
        return

    # 输入数据 - 147个样本
    input_data = np.array([
        [0.044995767, 0.233700393, 0.012892205, 0.184324649],
        [0.065722645, 0.231985544, 0.029807641, 0.183760876],
        [0.086453548, 0.230236930, 0.046720379, 0.183230426],
        [0.107206932, 0.228510490, 0.063604401, 0.182707887],
        [0.127922632, 0.226790954, 0.080473571, 0.182188158],
        [0.148621050, 0.225026893, 0.097295420, 0.181672730],
        [0.169314019, 0.223260278, 0.114058760, 0.181161780],
        [0.046433568, 0.254545430, 0.013385019, 0.201128160],
        [0.067184367, 0.252791930, 0.030299855, 0.200547739],
        [0.087985928, 0.251029676, 0.047218257, 0.199995798],
        [0.108800950, 0.249280715, 0.064119649, 0.199447175],
        [0.129615600, 0.247515082, 0.081003787, 0.198913059],
        [0.150365231, 0.245755440, 0.097837799, 0.198378724],
        [0.171129882, 0.244021059, 0.114623486, 0.197844550],
        [0.047879522, 0.275523325, 0.013861055, 0.217979503],
        [0.068677725, 0.273757855, 0.030794775, 0.217394670],
        [0.089562879, 0.271988523, 0.047714215, 0.216808824],
        [0.110423072, 0.270209068, 0.064639113, 0.216241619],
        [0.131265805, 0.268473624, 0.081529128, 0.215681774],
        [0.152151267, 0.266689022, 0.098381724, 0.215129597],
        [0.172972126, 0.264938690, 0.115188043, 0.214585379],
        [0.049315139, 0.296628868, 0.014321095, 0.234866342],
        [0.070182490, 0.294837639, 0.031272071, 0.234258475],
        [0.091123424, 0.293067725, 0.048213990, 0.233654500],
        [0.112065963, 0.291303375, 0.065145600, 0.233076055],
        [0.132984782, 0.289546924, 0.082052373, 0.232498879],
        [0.153933245, 0.287781527, 0.098925230, 0.231929695],
        [0.174878634, 0.286038339, 0.115753765, 0.231361356],
        [0.050773484, 0.317775419, 0.014793986, 0.251774277],
        [0.071697382, 0.315990380, 0.031745379, 0.251144644],
        [0.092682231, 0.314236961, 0.048700496, 0.250543385],
        [0.113703534, 0.312480515, 0.065648355, 0.249941747],
        [0.134740521, 0.310717262, 0.082574960, 0.249348134],
        [0.155767168, 0.308981668, 0.099469698, 0.248762814],
        [0.176817268, 0.307276974, 0.116317384, 0.248177115],
        [0.052242940, 0.339005414, 0.015246906, 0.268706086],
        [0.073247485, 0.337234658, 0.032210716, 0.268080801],
        [0.094298609, 0.335432169, 0.049183013, 0.267435926],
        [0.115397255, 0.333688641, 0.066150220, 0.266823292],
        [0.136506774, 0.331960929, 0.083101784, 0.266209987],
        [0.157635486, 0.330264316, 0.100016497, 0.265626661],
        [0.178764382, 0.328560080, 0.116890325, 0.265028298],
        [0.053738240, 0.360194981, 0.015693271, 0.285617629],
        [0.074802195, 0.358435348, 0.032670069, 0.284948268],
        [0.095946402, 0.356696459, 0.049664424, 0.284304578],
        [0.117127859, 0.354974021, 0.066652666, 0.283673593],
        [0.138340043, 0.353300307, 0.083627283, 0.283069031],
        [0.159531549, 0.351620062, 0.100562200, 0.282467358],
        [0.180754489, 0.349934246, 0.117481077, 0.281878935],
        [0.052420053, 0.234955867, 0.014192806, 0.182420877],
        [0.071629248, 0.233709187, 0.030337537, 0.181899311],
        [0.090821271, 0.232448319, 0.046452624, 0.181388028],
        [0.110005977, 0.231164586, 0.062535524, 0.180880647],
        [0.129156942, 0.229854580, 0.078577120, 0.180385489],
        [0.148328421, 0.228535553, 0.094568412, 0.179897674],
        [0.167411159, 0.227191766, 0.110492845, 0.179417698],
        [0.053445012, 0.254287744, 0.014676418, 0.198443266],
        [0.072687333, 0.252997872, 0.030810500, 0.197898056],
        [0.091944412, 0.251682239, 0.046935478, 0.197359459],
        [0.111191779, 0.250348622, 0.063035706, 0.196836189],
        [0.130445194, 0.249006225, 0.079088953, 0.196315374],
        [0.149611883, 0.247676663, 0.095098604, 0.195807341],
        [0.168777861, 0.246322877, 0.111043446, 0.195311379],
        [0.054465276, 0.273802736, 0.015129608, 0.214507968],
        [0.073761107, 0.272467660, 0.031287208, 0.213966932],
        [0.093080063, 0.271120468, 0.047411954, 0.213409740],
        [0.112394561, 0.269772268, 0.063519074, 0.212863414],
        [0.131698888, 0.268415114, 0.079591520, 0.212322506],
        [0.150956097, 0.267058513, 0.095622907, 0.211795484],
        [0.170258353, 0.265699370, 0.111582044, 0.211277330],
        [0.055466455, 0.293480335, 0.015577098, 0.230630279],
        [0.074841096, 0.292095374, 0.031740995, 0.230064797],
        [0.094222632, 0.290732683, 0.047887917, 0.229510493],
        [0.113613670, 0.289359198, 0.064001087, 0.228941604],
        [0.132996889, 0.287993912, 0.080089872, 0.228389356],
        [0.152347973, 0.286630522, 0.096137419, 0.227844856],
        [0.171705737, 0.285260755, 0.112136519, 0.227308456],
        [0.056494161, 0.313282941, 0.016008657, 0.246824622],
        [0.075928219, 0.311882394, 0.032184120, 0.246226419],
        [0.095384835, 0.310491574, 0.048345307, 0.245632377],
        [0.114848982, 0.309123442, 0.064475464, 0.245057191],
        [0.134325909, 0.307736909, 0.080583743, 0.244488885],
        [0.153777089, 0.306371403, 0.096649769, 0.243933134],
        [0.173205778, 0.305009356, 0.112677368, 0.243374075],
        [0.057519495, 0.333151503, 0.016429206, 0.263039625],
        [0.077032397, 0.331728906, 0.032618187, 0.262420032],
        [0.096544009, 0.330332020, 0.048795628, 0.261806519],
        [0.116099068, 0.328978673, 0.064943660, 0.261201574],
        [0.135654899, 0.327582856, 0.081074523, 0.260614051],
        [0.155163791, 0.326262297, 0.097163973, 0.260036600],
        [0.174692476, 0.324904196, 0.113212432, 0.259470834],
        [0.058588110, 0.353147206, 0.016840371, 0.279286510],
        [0.078154827, 0.351698978, 0.033044795, 0.278635055],
        [0.097759778, 0.350291698, 0.049230745, 0.278007203],
        [0.117380379, 0.348927561, 0.065409784, 0.277392235],
        [0.137023682, 0.347562215, 0.081560175, 0.276791031],
        [0.156641933, 0.346212034, 0.097681311, 0.276198680],
        [0.176273548, 0.344915862, 0.113753445, 0.275620463],
        [0.059383290, 0.238124162, 0.014688374, 0.180920309],
        [0.077287878, 0.237372209, 0.030192875, 0.180456085],
        [0.095201603, 0.236602042, 0.045636951, 0.179996261],
        [0.113077028, 0.235807727, 0.061053290, 0.179541487],
        [0.130913081, 0.234991307, 0.076425312, 0.179089165],
        [0.148706582, 0.234136055, 0.091734273, 0.178649635],
        [0.166457159, 0.233259748, 0.106973015, 0.178225603],
        [0.059974848, 0.255865557, 0.015132989, 0.196107793],
        [0.077935548, 0.255060702, 0.030638796, 0.195617058],
        [0.095887754, 0.254232824, 0.046076163, 0.195132602],
        [0.113833491, 0.253382871, 0.061509273, 0.194654689],
        [0.131750495, 0.252525995, 0.076901350, 0.194190161],
        [0.149601961, 0.251621339, 0.092225986, 0.193720631],
        [0.167412536, 0.250711600, 0.107482428, 0.193268567],
        [0.060541271, 0.273843102, 0.015549312, 0.211425554],
        [0.078581102, 0.272978224, 0.031057079, 0.210916758],
        [0.096592216, 0.272096684, 0.046510707, 0.210412115],
        [0.114587729, 0.271206688, 0.061958650, 0.209912001],
        [0.132578221, 0.270299575, 0.077361186, 0.209416786],
        [0.150513251, 0.269373040, 0.092709190, 0.208926826],
        [0.168427260, 0.268438981, 0.107985742, 0.208433523],
        [0.061159573, 0.292069754, 0.015953841, 0.226791277],
        [0.079248803, 0.291109622, 0.031472226, 0.226268879],
        [0.097333273, 0.290181219, 0.046941131, 0.225725508],
        [0.115409804, 0.289251298, 0.062398661, 0.225204058],
        [0.133430558, 0.288311926, 0.077812462, 0.224689536],
        [0.151457156, 0.287365906, 0.093175084, 0.224182416],
        [0.169439929, 0.286417377, 0.108484090, 0.223691510],
        [0.061724639, 0.310387460, 0.016344284, 0.242210553],
        [0.079896740, 0.309421449, 0.031877729, 0.241668640],
        [0.098031486, 0.308471080, 0.047370938, 0.241107079],
        [0.116162612, 0.307519208, 0.062820345, 0.240571985],
        [0.134300375, 0.306554516, 0.078260103, 0.240038293],
        [0.152418045, 0.305570997, 0.093642872, 0.239506375],
        [0.170524065, 0.304605163, 0.108964721, 0.239002718],
        [0.062309101, 0.328900018, 0.016714760, 0.257669630],
        [0.080549425, 0.327916539, 0.032260890, 0.257108469],
        [0.098759879, 0.326920196, 0.047790343, 0.256552697],
        [0.116992720, 0.325920190, 0.063264246, 0.255998284],
        [0.135197361, 0.324936300, 0.078698711, 0.255445057],
        [0.153444292, 0.323968506, 0.094100248, 0.254900172],
        [0.171598386, 0.322998661, 0.109465045, 0.254364011],
        [0.062900286, 0.347531355, 0.017073585, 0.273188854],
        [0.081201668, 0.346502470, 0.032632491, 0.272588678],
        [0.099503353, 0.345494047, 0.048172897, 0.272015519],
        [0.117843401, 0.344491445, 0.063694762, 0.271441831],
        [0.136161953, 0.343501729, 0.079156512, 0.270874601],
        [0.154456003, 0.342543872, 0.094580874, 0.270314111],
        [0.172735170, 0.341553079, 0.109960372, 0.269760623],





        #PCB 板的芯片引脚
        # [0.023459104, 0.181094805,	0.045696254, 0.205405337],
        # [0.025325625, 0.181087434,  0.047571516, 0.205393870],
        # [0.027192651, 0.181079856,  0.049447162, 0.205382295],
        # [0.029060168, 0.181072002,  0.051322848, 0.205370535],
        # [0.030926177, 0.181064018,  0.053197777, 0.205358736],
        # [0.032792738, 0.181055825,  0.055072727, 0.205346754],
        # [0.034659687, 0.181047368,  0.056948173, 0.205334729],
        # [0.036527099, 0.181038786,  0.058825950, 0.205322604],
        #
        # [0.001177879, 0.143681527,  0.017916202, 0.164035623],
        # [0.002669862, 0.143765315,  0.019409069, 0.164118294],
        # [0.004161965, 0.143849137,  0.020901949, 0.164201014],
        # [0.005654178, 0.143932936,  0.022394892, 0.164283723],
        # [0.007146498, 0.144016828,  0.023887894, 0.164366538],
        # [0.008638977, 0.144100753,  0.025380945, 0.164449344],
        # [0.010131485, 0.144184658,  0.026874100, 0.164532255],
        # [0.011624081, 0.144268657,  0.028367232, 0.164615217],
        #



        #更正后的坐标格式
        [0.023459104, 0.181094805, 0.001177879, 0.143681527],
        [0.025325625, 0.181087434, 0.002669862, 0.143765315],
        [0.027192651, 0.181079856, 0.004161965, 0.143849137],
        [0.029060168, 0.181072002, 0.005654178, 0.143932936],
        [0.030926177, 0.181064018, 0.007146498, 0.144016828],
        [0.032792738, 0.181055825, 0.008638977, 0.144100753],
        [0.034659687, 0.181047368, 0.010131485, 0.144184658],
        [0.036527099, 0.181038786, 0.011624081, 0.144268657],
        [0.045696254, 0.205405337, 0.017916202, 0.164035623],
        [0.047571516, 0.205393870, 0.019409069, 0.164118294],
        [0.049447162, 0.205382295, 0.020901949, 0.164201014],
        [0.051322848, 0.205370535, 0.022394892, 0.164283723],
        [0.053197777, 0.205358736, 0.023887894, 0.164366538],
        [0.055072727, 0.205346754, 0.025380945, 0.164449344],
        [0.056948173, 0.205334729, 0.026874100, 0.164532255],
         [0.058825950, 0.205322604, 0.028367232, 0.164615217],

    ])

    print(f"输入数据形状: {input_data.shape}")

    # 进行预测
    predictions = predict_with_model(model, scaler_X, scaler_y, input_data)

    print(f"预测结果形状: {predictions.shape}")

    # 创建DataFrame以便更好地显示结果
    results_df = pd.DataFrame({
        'Input1': input_data[:, 0]*10000,
        'Input2': input_data[:, 1]*10000,
        'Input3': input_data[:, 2]*10000,
        'Input4': input_data[:, 3]*10000,
        'Output1': predictions[:, 0]*10000,
        'Output2': predictions[:, 1]*10000,
        'Output3': predictions[:, 2]*10000
    })

    # 显示前10个结果
    print("\n前10个预测结果:")
    print(results_df.head(147+16).to_string(index=False, float_format='%.8f'))

    # 保存所有结果到CSV文件
    results_df.to_csv('prediction_results_target_loss.csv', index=False, float_format='%.8f')
    print(f"\n所有预测结果已保存到 'prediction_results_target_loss.csv'")

    # 显示统计信息
    print("\n预测结果统计:")
    print(f"Output1 - 均值: {predictions[:, 0].mean():.8f}, 标准差: {predictions[:, 0].std():.8f}")
    print(f"Output2 - 均值: {predictions[:, 1].mean():.8f}, 标准差: {predictions[:, 1].std():.8f}")
    print(f"Output3 - 均值: {predictions[:, 2].mean():.8f}, 标准差: {predictions[:, 2].std():.8f}")

    # 计算与期望值的差异（如果有期望值的话）
    # 注意：这里我们没有期望值，所以只显示预测结果

    print(f"\n验证完成！共处理 {len(input_data)} 个输入样本。")


if __name__ == "__main__":
    main()